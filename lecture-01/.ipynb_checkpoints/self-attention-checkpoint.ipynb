{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48c62c8",
   "metadata": {},
   "source": [
    "## what's the self-attention? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0014a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0139faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 4\n",
    "dim = 32\n",
    "length = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65fc7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(batch, length, dim) # batch, length, vector-dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b80f38a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b63287ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2287, -0.1237, -0.0114,  1.5521, -1.0304,  0.9804,  0.1499, -0.6190,\n",
       "         1.1966, -0.0468, -0.4214, -0.4172, -0.4895,  0.5500, -1.1692, -0.1066,\n",
       "         0.1798, -0.1861, -1.7311, -0.5634, -0.9203,  0.4252,  1.1050, -0.0987,\n",
       "        -0.2975, -0.0341, -0.0478,  1.7376, -1.1968, -0.8195, -0.7322,  1.7068])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0] # some word's initial representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce737598",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(length, length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a38fbfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "274ef304",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.zeros(length, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76d87b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea7df2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights.masked_fill(tril == 0, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43f1eaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74e493a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f958f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = F.softmax(weights, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e41371b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d4ef017",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = weights @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1f2fe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2873e-01, -1.2372e-01, -1.1437e-02,  ..., -8.1952e-01,\n",
       "          -7.3220e-01,  1.7068e+00],\n",
       "         [ 3.1518e-01,  4.5397e-01,  3.6987e-01,  ..., -1.8477e-01,\n",
       "           4.5158e-01,  4.2963e-01],\n",
       "         [ 6.7803e-01,  2.7806e-01,  4.3219e-01,  ..., -6.0472e-01,\n",
       "           4.8114e-02,  1.1949e-01],\n",
       "         ...,\n",
       "         [ 5.5755e-01,  7.1188e-01,  3.9822e-01,  ..., -3.5320e-01,\n",
       "           1.4337e-03, -3.4887e-01],\n",
       "         [ 3.1575e-01,  7.8707e-01,  2.5335e-01,  ..., -2.6284e-01,\n",
       "          -1.3354e-01, -4.9160e-01],\n",
       "         [ 3.1321e-01,  7.7063e-01,  7.2988e-02,  ..., -3.0235e-01,\n",
       "          -1.2208e-01, -5.6847e-01]],\n",
       "\n",
       "        [[ 3.2266e-01, -5.5382e-01, -3.3814e-01,  ..., -1.2027e+00,\n",
       "          -7.4612e-01, -1.0881e+00],\n",
       "         [-1.7338e-01,  6.1709e-01, -4.0853e-01,  ..., -5.3127e-01,\n",
       "          -1.7906e-01, -2.4196e-01],\n",
       "         [-1.4671e-01,  2.2366e-01,  7.4242e-02,  ...,  2.5735e-01,\n",
       "          -2.2835e-01, -1.9535e-01],\n",
       "         ...,\n",
       "         [ 1.6050e-01, -2.6026e-02,  6.2035e-02,  ..., -2.7855e-01,\n",
       "           5.8624e-02, -1.4875e-01],\n",
       "         [ 1.8934e-01, -3.4913e-02,  1.2164e-01,  ..., -3.4255e-01,\n",
       "          -1.1971e-01, -1.8346e-01],\n",
       "         [ 1.5077e-01, -7.7825e-02,  8.6115e-02,  ..., -2.4679e-01,\n",
       "          -2.1988e-01, -3.3257e-01]],\n",
       "\n",
       "        [[-8.2584e-01,  2.1350e-02, -5.0738e-01,  ..., -1.0995e+00,\n",
       "          -2.7936e-01,  5.1191e-02],\n",
       "         [-7.3258e-02,  6.8098e-01, -6.3718e-01,  ...,  4.7788e-01,\n",
       "           4.5057e-02, -1.7967e-01],\n",
       "         [-2.2512e-01, -1.1599e-01,  3.4114e-01,  ...,  4.4167e-01,\n",
       "           2.6016e-01, -8.8221e-02],\n",
       "         ...,\n",
       "         [ 1.0162e-01,  3.2296e-01,  8.2871e-01,  ...,  5.5479e-01,\n",
       "           3.4735e-02, -2.8578e-01],\n",
       "         [-1.5184e-02,  2.0672e-01,  7.9432e-01,  ...,  5.3405e-01,\n",
       "          -4.0351e-02, -1.3669e-01],\n",
       "         [-4.8589e-02,  2.0764e-02,  7.0144e-01,  ...,  4.7774e-01,\n",
       "          -3.4101e-01,  5.6365e-02]],\n",
       "\n",
       "        [[-5.6214e-01, -1.0818e+00, -1.6121e+00,  ..., -6.8670e-01,\n",
       "          -1.0852e-01, -5.5848e-01],\n",
       "         [-5.4859e-01, -6.6737e-03, -7.7790e-01,  ..., -9.6588e-02,\n",
       "          -3.8424e-01,  2.2338e-01],\n",
       "         [-4.5100e-01, -2.4029e-01, -4.0707e-01,  ...,  2.0531e-01,\n",
       "           3.5937e-01,  7.8829e-02],\n",
       "         ...,\n",
       "         [-2.9283e-01, -1.0737e-01, -2.9585e-01,  ..., -8.8687e-02,\n",
       "          -1.6140e-01,  4.3343e-02],\n",
       "         [-2.1559e-01,  7.5881e-03, -3.3161e-01,  ...,  1.1346e-01,\n",
       "          -2.7994e-01, -1.1963e-01],\n",
       "         [-3.1123e-01, -2.4401e-01, -1.7073e-01,  ...,  2.1283e-01,\n",
       "           5.0435e-03, -9.8528e-02]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d8518",
   "metadata": {},
   "source": [
    "## add some learnable components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b482b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65a85b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(dim, head_size, bias=False)\n",
    "query = nn.Linear(dim, head_size, bias=False)\n",
    "\n",
    "k = key(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d439fada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88f2faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = query(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0232fa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f72767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = q@k.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4030cb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b083dd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6622, -0.8045, -0.4547, -0.5178, -1.8640, -0.1153, -0.8735,\n",
       "          -0.2420],\n",
       "         [-0.4997, -0.7454,  0.1323, -0.1676, -2.2134, -3.3614, -1.5745,\n",
       "           0.3952],\n",
       "         [ 0.8349,  0.6129, -1.0411, -0.1623,  2.5310,  2.4834,  0.5778,\n",
       "          -0.3231],\n",
       "         [-0.1163,  0.2566, -0.9266, -0.4559,  1.3923,  0.4611,  0.2469,\n",
       "          -0.6366],\n",
       "         [ 0.5025,  0.0474, -2.5849,  0.0661,  0.6871, -3.0180,  2.0473,\n",
       "           0.4873],\n",
       "         [ 0.3404,  1.0072, -0.7737,  0.7192,  0.7938, -0.0130,  0.4553,\n",
       "          -1.0714],\n",
       "         [-1.0977, -1.9826, -0.8031,  0.3475, -1.5062, -2.5116, -0.3329,\n",
       "           1.3282],\n",
       "         [-0.2474,  0.0376, -0.9917, -0.3229, -0.8140, -0.6114, -0.0665,\n",
       "           0.0286]],\n",
       "\n",
       "        [[-1.3017, -1.4547,  1.7709, -0.8887,  1.0936,  0.5941, -0.1536,\n",
       "           1.1183],\n",
       "         [-0.9009, -1.9717,  0.4046,  0.1534,  0.7292, -0.7345, -0.0698,\n",
       "          -0.4895],\n",
       "         [-1.8335,  0.0600,  1.9100, -1.2072,  1.2051,  0.1280, -1.1493,\n",
       "          -0.4606],\n",
       "         [-0.4591, -0.5550,  0.7732, -0.4994,  1.2047, -0.0736,  0.0327,\n",
       "           0.0307],\n",
       "         [ 1.6886,  1.8056, -1.4219,  1.1403, -2.1804,  2.2324,  0.3303,\n",
       "          -0.2911],\n",
       "         [ 0.8123, -0.9777,  0.0675,  0.9773,  0.7329, -0.7606, -0.6220,\n",
       "          -0.7527],\n",
       "         [ 2.1575,  0.4268,  0.7350,  0.7237, -1.7600,  2.1437, -1.0388,\n",
       "           1.4022],\n",
       "         [ 0.9410,  1.2167,  0.6357, -1.3445,  0.2916, -0.2109, -0.8683,\n",
       "          -0.0367]],\n",
       "\n",
       "        [[-0.2595, -0.7971,  0.8661,  0.1556, -1.0622, -0.2486,  0.4780,\n",
       "           0.6901],\n",
       "         [ 0.1140, -0.6194, -0.3444, -1.2075, -0.9395,  0.3107,  1.2369,\n",
       "           0.5754],\n",
       "         [ 0.8085,  1.5379, -0.9460, -0.6324, -0.2333,  1.9484,  0.5533,\n",
       "          -0.0604],\n",
       "         [-0.5681, -1.2201,  2.4690,  1.4606,  1.1290, -1.8283,  0.4253,\n",
       "           0.9234],\n",
       "         [-0.3370, -2.3889, -0.0272, -0.7216, -1.1119, -1.6560,  1.6006,\n",
       "           2.1839],\n",
       "         [-0.5914,  0.4890,  0.0665, -0.3137, -0.0132, -0.0823, -0.0681,\n",
       "          -0.1278],\n",
       "         [ 0.8673,  2.2896, -1.9723, -0.9199,  0.1535,  2.6957, -1.0073,\n",
       "          -2.1811],\n",
       "         [-0.2726, -1.3038,  1.0991,  0.4652, -0.0304, -0.4739,  0.3501,\n",
       "           0.0346]],\n",
       "\n",
       "        [[ 1.4086,  0.1221, -0.1359,  0.6214,  0.9187, -0.2232,  0.4260,\n",
       "          -0.0431],\n",
       "         [-0.9340,  0.2313,  0.8389,  2.3390,  0.0761,  0.6767, -0.8377,\n",
       "           0.6949],\n",
       "         [ 0.2322,  0.7320,  0.0095, -0.8682,  0.7510, -0.5719,  0.3787,\n",
       "          -0.5660],\n",
       "         [ 1.0040,  0.4591,  1.3497,  0.8208,  1.8292, -0.1559,  0.9577,\n",
       "          -0.0564],\n",
       "         [ 0.7589, -0.9177, -0.0994,  1.8154,  0.0467,  1.1896, -1.4377,\n",
       "           0.2963],\n",
       "         [-0.6902,  0.5801, -0.8696,  1.0009,  1.3559,  0.1109,  0.3068,\n",
       "          -0.2918],\n",
       "         [ 0.7669, -0.9620, -0.6357,  0.9860, -0.8231, -0.6652,  1.3891,\n",
       "           0.1182],\n",
       "         [-1.0644,  0.9270,  0.2959,  0.0915, -0.1685, -2.1611,  1.7911,\n",
       "          -0.3154]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97efa0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = F.softmax(weights.masked_fill(tril==0, float('-inf')), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e3f9b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5611, 0.4389, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5117, 0.4099, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2771, 0.4023, 0.1232, 0.1973, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2833, 0.1798, 0.0129, 0.1831, 0.3408, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1426, 0.2778, 0.0468, 0.2083, 0.2244, 0.1001, 0.0000, 0.0000],\n",
       "         [0.0995, 0.0411, 0.1335, 0.4220, 0.0661, 0.0242, 0.2137, 0.0000],\n",
       "         [0.1331, 0.1771, 0.0633, 0.1235, 0.0756, 0.0925, 0.1595, 0.1755]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.7448, 0.2552, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0200, 0.1331, 0.8468, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1588, 0.1443, 0.5445, 0.1525, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3613, 0.4062, 0.0161, 0.2088, 0.0075, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2530, 0.0422, 0.1201, 0.2984, 0.2337, 0.0525, 0.0000, 0.0000],\n",
       "         [0.3699, 0.0655, 0.0892, 0.0882, 0.0074, 0.3648, 0.0151, 0.0000],\n",
       "         [0.2205, 0.2905, 0.1625, 0.0224, 0.1152, 0.0697, 0.0361, 0.0830]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6756, 0.3244, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3080, 0.6387, 0.0533, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0334, 0.0174, 0.6955, 0.2537, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2752, 0.0354, 0.3752, 0.1874, 0.1268, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0940, 0.2768, 0.1814, 0.1240, 0.1675, 0.1563, 0.0000, 0.0000],\n",
       "         [0.0817, 0.3388, 0.0048, 0.0137, 0.0400, 0.5085, 0.0125, 0.0000],\n",
       "         [0.0787, 0.0281, 0.3103, 0.1646, 0.1003, 0.0644, 0.1467, 0.1070]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2377, 0.7623, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2900, 0.4780, 0.2321, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2614, 0.1516, 0.3694, 0.2176, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2009, 0.0376, 0.0852, 0.5778, 0.0985, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0481, 0.1713, 0.0402, 0.2610, 0.3722, 0.1072, 0.0000, 0.0000],\n",
       "         [0.2010, 0.0357, 0.0494, 0.2503, 0.0410, 0.0480, 0.3745, 0.0000],\n",
       "         [0.0265, 0.1944, 0.1034, 0.0843, 0.0650, 0.0089, 0.4613, 0.0561]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d065fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = weights@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c1c8478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2287, -0.1237, -0.0114,  ..., -0.8195, -0.7322,  1.7068],\n",
       "         [ 0.2487,  0.3834,  0.3233,  ..., -0.2623,  0.3069,  0.5857],\n",
       "         [ 0.3451,  0.3537,  0.3457,  ..., -0.3482,  0.2361,  0.4868],\n",
       "         ...,\n",
       "         [ 0.4575,  0.8141,  0.4379,  ..., -0.0488,  0.1515, -0.4681],\n",
       "         [ 0.4394,  0.5329,  0.2454,  ...,  0.0430, -0.7996, -0.2245],\n",
       "         [ 0.2497,  0.7764, -0.0251,  ..., -0.1822, -0.0613, -0.5465]],\n",
       "\n",
       "        [[ 0.3227, -0.5538, -0.3381,  ..., -1.2027, -0.7461, -1.0881],\n",
       "         [ 0.0694,  0.0439, -0.3741,  ..., -0.8599, -0.4566, -0.6561],\n",
       "         [-0.1617, -0.2500,  0.8100,  ...,  1.5481, -0.2401, -0.0278],\n",
       "         ...,\n",
       "         [ 0.5280, -0.3127,  0.0021,  ..., -0.8125, -0.0221, -0.3066],\n",
       "         [-0.0226, -0.2833,  0.0485,  ..., -0.2883, -0.0581, -0.5557],\n",
       "         [-0.0417,  0.2381, -0.0375,  ..., -0.0780, -0.1851, -0.1739]],\n",
       "\n",
       "        [[-0.8258,  0.0213, -0.5074,  ..., -1.0995, -0.2794,  0.0512],\n",
       "         [-0.3375,  0.4494, -0.5916,  ..., -0.0760, -0.0689, -0.0986],\n",
       "         [ 0.1514,  0.7717, -0.5237,  ...,  0.9938,  0.1867, -0.2414],\n",
       "         ...,\n",
       "         [ 0.2350,  0.4424,  0.7391,  ...,  0.8678,  0.1161, -0.2722],\n",
       "         [ 0.4667,  1.4428,  0.1175,  ...,  1.2054, -0.1185, -0.3208],\n",
       "         [-0.2530, -0.5668,  1.2244,  ...,  0.2998, -0.1820,  0.0655]],\n",
       "\n",
       "        [[-0.5621, -1.0818, -1.6121,  ..., -0.6867, -0.1085, -0.5585],\n",
       "         [-0.5415,  0.5573, -0.3403,  ...,  0.2130, -0.5289,  0.6335],\n",
       "         [-0.4781,  0.0328, -0.3629,  ...,  0.2245,  0.0817,  0.2697],\n",
       "         ...,\n",
       "         [ 0.0822,  0.2332,  0.0204,  ..., -0.1667, -0.9656,  0.0325],\n",
       "         [-0.0447,  0.0933, -0.4929,  ...,  0.3106, -0.3693, -0.6586],\n",
       "         [-0.0289,  0.3512, -0.1622,  ...,  0.7758, -0.4447, -0.4013]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e972179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = nn.Linear(dim, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66daf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e8b4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = weights@v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5060341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9893e-01,  3.8479e-01, -3.6142e-01,  6.3646e-01, -5.0286e-02,\n",
       "           8.3531e-01, -5.3619e-01, -1.9481e-01,  3.1110e-01, -5.5768e-01,\n",
       "           2.1076e-01,  2.7252e-02, -1.1323e-01, -4.5328e-01,  1.8950e-02,\n",
       "          -2.8733e-01],\n",
       "         [ 7.9644e-02, -1.8328e-01, -3.9564e-01,  7.2709e-01,  1.7089e-01,\n",
       "           4.4149e-01, -9.7890e-02, -3.2651e-01, -1.1713e-01, -5.2378e-01,\n",
       "           3.0402e-01, -1.3787e-02, -1.8326e-01, -3.0585e-01, -2.4682e-01,\n",
       "          -7.2937e-01],\n",
       "         [ 1.9335e-02, -2.1036e-01, -3.1194e-01,  6.5323e-01,  1.0102e-01,\n",
       "           4.6333e-01, -1.2477e-01, -2.5036e-01, -1.7927e-01, -5.7722e-01,\n",
       "           3.1218e-01,  2.7355e-02, -1.3516e-01, -3.2260e-01, -2.3864e-01,\n",
       "          -6.4317e-01],\n",
       "         [ 8.3087e-02, -5.1429e-01, -1.3816e-01,  4.4450e-01,  6.4652e-02,\n",
       "           4.1198e-01, -1.0456e-01, -1.0758e-01, -3.7490e-01, -5.9400e-01,\n",
       "           2.4498e-01,  6.7987e-02, -1.2052e-01, -2.3250e-01, -2.7626e-01,\n",
       "          -6.4838e-01],\n",
       "         [-9.7687e-02, -4.8168e-01, -2.0597e-01,  3.9112e-01,  3.7185e-01,\n",
       "           3.7167e-01, -1.5687e-01, -3.1533e-01,  2.2187e-02, -1.8777e-01,\n",
       "           2.4525e-01, -2.3365e-01,  2.2599e-01, -8.9205e-02, -3.5867e-01,\n",
       "          -5.1843e-01],\n",
       "         [ 1.0307e-02, -5.7729e-01, -1.4059e-01,  3.3497e-01,  3.0141e-01,\n",
       "           2.4287e-01, -1.2946e-01, -2.7324e-01, -1.8395e-01, -2.5623e-01,\n",
       "           1.8798e-01, -1.8674e-01,  6.6497e-02,  1.0317e-03, -3.2769e-01,\n",
       "          -5.6770e-01],\n",
       "         [ 1.1942e-01, -7.5895e-01,  1.0177e-01, -1.1061e-02,  3.9479e-02,\n",
       "           4.8057e-01, -8.2662e-02,  5.6201e-03, -1.6331e-01, -2.8526e-01,\n",
       "           1.0615e-01, -5.5358e-02,  2.5946e-01, -3.0627e-01, -2.0943e-01,\n",
       "          -4.4100e-01],\n",
       "         [ 1.3298e-01, -4.1464e-01, -3.7651e-01,  3.2095e-01,  1.6536e-01,\n",
       "           4.3341e-01, -1.7429e-01, -4.9847e-01,  7.9386e-03, -1.4073e-01,\n",
       "           2.7465e-01, -2.2266e-01,  4.0011e-01, -2.4467e-01, -4.2240e-01,\n",
       "          -5.0301e-01]],\n",
       "\n",
       "        [[ 3.2005e-01,  1.0647e-01,  5.0789e-01,  3.8524e-01, -2.9900e-01,\n",
       "           5.1469e-01, -1.6827e-01, -8.0717e-01,  5.4697e-01, -1.0220e-01,\n",
       "          -2.4411e-01, -2.9932e-01, -3.9785e-01,  6.8933e-01,  6.9703e-02,\n",
       "          -7.2163e-02],\n",
       "         [ 2.5779e-01,  8.5267e-02,  4.5630e-01,  2.1611e-01, -1.1960e-01,\n",
       "           5.0387e-01, -2.3106e-01, -8.0840e-01,  4.3603e-01, -2.2359e-02,\n",
       "          -1.2793e-01, -3.3032e-01, -2.9595e-01,  6.7585e-01, -9.2980e-02,\n",
       "          -7.9125e-02],\n",
       "         [ 7.6100e-01, -1.3254e+00,  5.9184e-01, -3.5110e-01,  3.3710e-01,\n",
       "          -5.7300e-01,  7.4035e-01,  1.0785e-01, -1.0512e-01, -1.6896e-02,\n",
       "           2.9454e-01,  7.2206e-02, -8.8945e-01,  4.6824e-01,  1.5953e-01,\n",
       "          -6.4393e-01],\n",
       "         [ 7.2500e-01, -8.2963e-01,  5.8254e-01, -1.0157e-01,  1.8950e-01,\n",
       "          -2.5935e-01,  4.9110e-01, -1.3827e-01,  8.8391e-02,  7.6984e-02,\n",
       "           1.5509e-01, -2.4170e-01, -6.1424e-01,  4.0723e-01,  7.8639e-02,\n",
       "          -5.9228e-01],\n",
       "         [ 4.1084e-01,  2.9823e-02,  4.6711e-01,  1.3178e-01,  4.9717e-02,\n",
       "           3.7931e-01, -1.2449e-01, -6.6784e-01,  3.4199e-01,  1.6740e-01,\n",
       "          -7.9310e-03, -5.7032e-01, -1.3567e-01,  4.6548e-01, -1.9966e-01,\n",
       "          -2.9328e-01],\n",
       "         [ 4.6094e-01, -1.2277e-01,  3.9268e-01,  1.4759e-01, -6.8732e-02,\n",
       "           2.4192e-01,  2.1233e-01, -5.9335e-02,  4.7968e-01,  2.5856e-02,\n",
       "           7.5859e-02, -3.1209e-01, -1.1834e-01,  4.1447e-02,  7.4106e-02,\n",
       "          -1.9633e-01],\n",
       "         [ 2.3921e-01,  1.9640e-01,  3.7297e-01,  5.9637e-01,  6.6549e-02,\n",
       "           2.1893e-01, -1.2219e-01, -2.5368e-01,  4.7933e-01,  1.4049e-02,\n",
       "          -2.4883e-01, -4.4061e-01, -3.3110e-01,  5.1130e-01, -1.3970e-01,\n",
       "          -3.8596e-02],\n",
       "         [ 1.1783e-01, -2.2129e-01,  3.5531e-01, -1.1775e-02,  1.3384e-01,\n",
       "           2.1063e-01, -3.4059e-02, -1.9192e-01,  1.4936e-01, -1.2328e-01,\n",
       "           8.2189e-02, -7.5465e-02, -2.4151e-01,  4.7887e-01,  1.8574e-02,\n",
       "           7.9687e-02]],\n",
       "\n",
       "        [[-2.4867e-01,  2.5209e-01, -2.5454e-01,  6.5864e-01, -2.2597e-01,\n",
       "           2.0829e-01, -1.4152e-01,  4.4681e-01, -5.2879e-01, -1.6819e-01,\n",
       "           4.1469e-01,  1.9113e-01,  2.4669e-01, -1.8721e-01, -3.7095e-01,\n",
       "           3.7553e-01],\n",
       "         [-1.1170e-01, -6.8912e-02, -3.6543e-01,  3.4936e-01, -4.7432e-02,\n",
       "           2.7979e-01, -2.1819e-01,  3.8199e-01, -5.5031e-01, -2.9792e-02,\n",
       "           3.2017e-01,  8.5230e-02, -4.1700e-02, -9.4676e-02, -4.0892e-01,\n",
       "           3.2953e-01],\n",
       "         [ 8.2124e-03, -3.0435e-01, -4.7331e-01,  2.5844e-02,  1.5273e-01,\n",
       "           2.7676e-01, -2.7747e-01,  2.9767e-01, -5.3287e-01,  1.1752e-01,\n",
       "           2.2976e-01,  8.2591e-03, -3.2122e-01,  1.6878e-02, -4.7375e-01,\n",
       "           2.7319e-01],\n",
       "         [-2.6124e-01,  1.1453e+00, -2.5541e-01,  1.6058e-01,  1.1400e-01,\n",
       "          -8.6525e-01,  1.1532e-01, -1.5354e-01,  1.6141e-01, -7.6662e-02,\n",
       "           4.2949e-01,  6.0764e-01,  2.0633e-01,  1.9091e-01, -8.0941e-01,\n",
       "           2.4211e-02],\n",
       "         [-1.7560e-01,  6.4961e-01, -1.7269e-01,  2.1839e-01,  3.0684e-02,\n",
       "          -4.3915e-01,  4.3780e-02,  3.6609e-02, -1.0575e-01, -1.4409e-01,\n",
       "           3.0307e-01,  3.9321e-01,  9.1834e-02,  2.1137e-02, -6.8377e-01,\n",
       "           5.4505e-02],\n",
       "         [ 1.0434e-01, -3.4618e-02, -2.5121e-01,  1.6204e-03,  8.3629e-02,\n",
       "          -9.0152e-02, -2.9134e-02,  9.2646e-02, -1.7927e-01, -2.9622e-02,\n",
       "           1.4869e-01,  2.1079e-01, -9.8947e-02, -1.0639e-01, -6.3467e-01,\n",
       "           2.4171e-02],\n",
       "         [ 4.1827e-01, -6.5571e-01, -4.1853e-01,  2.4545e-02, -4.2008e-02,\n",
       "           2.8934e-01, -6.6809e-02,  1.8782e-01, -1.2585e-01,  1.1309e-01,\n",
       "           1.2745e-01,  1.4978e-01,  6.9487e-02, -3.6849e-01, -5.0898e-01,\n",
       "           8.6960e-02],\n",
       "         [-1.6729e-01,  6.3483e-01, -1.1521e-01,  1.3121e-01,  1.2336e-02,\n",
       "          -5.0733e-01,  1.3412e-01, -1.4443e-01, -8.2478e-02, -4.9561e-02,\n",
       "           7.1133e-02,  4.1514e-01,  7.9982e-02,  6.3316e-02, -5.2698e-01,\n",
       "           1.3887e-02]],\n",
       "\n",
       "        [[ 5.8001e-01,  1.9148e-01,  1.2936e-01,  2.6138e-01,  5.9836e-01,\n",
       "           6.6563e-01,  2.8830e-01,  7.5346e-01,  6.1779e-01,  4.7251e-01,\n",
       "           1.1915e-01, -8.7078e-01,  3.8682e-01,  4.1927e-01,  1.4812e+00,\n",
       "           4.2114e-01],\n",
       "         [-1.9168e-01,  1.6467e-01, -8.2401e-01,  3.3576e-01,  3.0920e-01,\n",
       "          -3.7485e-02, -5.1530e-01,  1.8971e-01,  4.8520e-01, -1.6903e-01,\n",
       "          -2.6507e-01,  4.8701e-01,  1.5794e-01,  5.5647e-01,  3.6249e-01,\n",
       "           8.7547e-01],\n",
       "         [ 6.0794e-02,  3.6510e-01, -5.8054e-01,  1.9988e-01,  1.5096e-01,\n",
       "           1.4174e-01, -1.7429e-01,  2.5231e-01,  3.3876e-01, -2.4419e-02,\n",
       "          -7.4724e-02,  2.2559e-01,  2.5573e-01,  2.6676e-01,  2.0247e-01,\n",
       "           4.3060e-01],\n",
       "         [ 1.7147e-01,  6.6310e-01, -3.5662e-01,  1.7222e-01,  4.6843e-02,\n",
       "           3.0371e-01, -4.0885e-02,  4.0202e-01,  3.0171e-01,  1.9775e-01,\n",
       "           1.6111e-01, -2.4982e-03,  1.4153e-01, -6.6633e-02, -2.2732e-02,\n",
       "           1.5636e-01],\n",
       "         [-5.8842e-02,  6.2634e-01, -2.3535e-01,  3.6955e-01,  2.6956e-01,\n",
       "           1.8552e-01, -4.0348e-01,  5.4327e-01,  5.6109e-01,  3.9924e-01,\n",
       "           2.1585e-01, -1.2951e-01, -1.5324e-01, -5.1191e-02,  1.4467e-01,\n",
       "           4.9338e-01],\n",
       "         [-1.8568e-01,  6.7997e-02, -7.1070e-02,  8.4006e-02,  1.7139e-01,\n",
       "          -3.9941e-01, -3.4835e-01, -4.1181e-03,  3.6610e-01,  2.0165e-01,\n",
       "          -1.4330e-03, -1.8689e-02,  2.9615e-01,  1.0651e-01,  1.4540e-01,\n",
       "           3.2928e-01],\n",
       "         [ 1.6010e-01, -2.5349e-01, -2.5122e-01,  4.9736e-02,  3.2373e-02,\n",
       "           3.1940e-01, -2.3283e-01,  3.1855e-01,  3.2293e-01, -2.4773e-02,\n",
       "          -1.1066e-01,  2.3694e-02,  7.2385e-02,  6.7415e-02,  4.2169e-01,\n",
       "           2.7135e-01],\n",
       "         [ 1.2585e-01, -4.9344e-01, -4.8112e-01,  1.5869e-02, -9.2210e-02,\n",
       "           1.5124e-01, -2.3726e-01,  8.0342e-02,  1.5885e-01, -3.0298e-01,\n",
       "          -2.4539e-01,  3.4222e-01,  1.4677e-01,  1.1934e-01,  1.8520e-01,\n",
       "           7.1914e-02]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7238b9",
   "metadata": {},
   "source": [
    "# train of GPT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e925f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        weight = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        weight = weight.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        weight = F.softmax(weight, dim=-1) # (B, T, T)\n",
    "        weight = self.dropout(weight)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = weight @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f154de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc89dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f751a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8df44a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "940687fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.788929 M parameters\n"
     ]
    }
   ],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = GPTLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c5d680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498aceb",
   "metadata": {},
   "source": [
    "## Homework & Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe121655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for iter in range(max_iters):\n",
    "     # every once in a while evaluate the loss on train and val sets\n",
    "    \n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
